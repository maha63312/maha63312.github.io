---
layout: portfolio_post
title: "Uge 45 – Evaluering af LLM-modeller og reduktion af hallucinationer"
week: 45
categories: ["snippets"]
elective:
  - "Backend-udvikling og API-design"
  - "Machine Learning og AI"
goals: |
  Undersøge risiko for hallucinationer i LLM-output og evaluere hvilke modeller, der bedst understøtter strukturerede outputs og JSON-schema.  Implementere LLM ved at refaktorere HLD og LLD.  
process: |
  Læse op på teknikker til reduktion af hallucinationer, udarbejde krav til modellen og evaluere Gemini, Claude og GPT-4.1 via praktiske tests.
result: |

  Som tidligere nævnt i min portfolio (https://maha63312.github.io/2025/10/10/uge41no2.html) vurderede jeg, at det ville give god mening at gennemføre et eksperiment, hvor en Large Language Model (LLM) beriger OCR-data med yderligere metadata. Når man arbejder med LLM’er, er der flere forhold, man skal tage højde for, og et af de vigtigste er, hvordan man reducerer risikoen for hallucinationer i modellens output.

  Hallucination opstår, når modellen “finder på” plausible, men forkerte oplysninger baseret på sandsynligheder i sit træningsmateriale. En LLM vil altid forsøge at give et svar – også selvom den mangler nødvendig viden. I modsætning til mennesker udviser modellen ikke usikkerhed, og den kan fortsætte med at generere fejlagtigt indhold uden at være klar over det selv. Dette kan føre til, at én hallucination efterfølges af yderligere påstande, der understøtter det oprindelige fejlagtige svar (kilde: https://medium.com/@nirdiamant21/llm-hallucinations-explained-8c76cdd82532).

  Der findes ingen metode, der fuldstændigt eliminerer hallucinationer, men en række tilgange kan reducere forekomsten markant:

  - **Retrieval-Augmented Generation (RAG)**  
    Modellen får adgang til opdaterede fakta i runtime, som hentes før der genereres et svar.

  - **Fine-tuning og alignment**  
    Modellen trænes på domænespecifikke data og kan instrueres i at svare mere forsigtigt.

  - **Prompt engineering**  
    Input formuleres med kontekst, regler, eksempler og eksplicitte begrænsninger.

  - **Rule-based post-processing og guardrails**  
    Backend kan validere eller korrigere modellens output.

  - **Confidence scoring**  
    Modellen estimerer selv sikkerheden for sit svar.

  - **Self-reflection og iterative refinement**  
    Modellen evaluerer sit eget svar og forbedrer det gennem iteration.

  ---

  ## Krav til modellen

  På baggrund af disse hensyn opstillede jeg følgende krav til den LLM, der skal anvendes i projektet. Modellen skal kunne:

  - returnere output i et JSON-schema  
  - klassificere en maskine ud fra et modelnummer  
  - modtage en prompt med indbygget kontekst, eksempler og værn  
  - være gratis eller have nok credits til et Proof of Concept (min. 100 gratis kald)

  De modeller, der bedst opfylder kravene, er:

  - **GPT-4.1**  
  - **Claude 3.5 Sonnet**  
  - **Gemini**  

  Alle tre modeller understøtter strukturerede outputs og er stærke i kontekstforståelse.

  ---

  ## Strukturerede outputs og JSON-schema

  Strukturerede outputs giver:

  - forudsigeligt output, som er let at parse  
  - garanti for format og datatyper  
  - mulighed for programmatisk håndtering af afvisninger  
  - ingen tekst udenfor JSON  
  - ingen outputs i forkert format  

  JSON-schema fungerer som en kontrakt mellem backend og LLM. Modellen må kun returnere værdier, der stemmer overens med schemaet.

  **Billede**  
  /assets/images/json_response_schema.png`

  Her ses et udsnit af JSON-schemaet med typer, felter og et enum for statustyperne "success" og "refusal".

  ---

  ## Evaluering af modellerne

  ### **Gemini**
  **Fordele:**
  - Understøtter strict JSON via Structured Outputs  
  - Hurtig og billig løsning (særligt Flash-modeller)  
  - God til dataudtræk og klassifikation  

  **Afgrænsninger:**
  - Mindre stabil i komplekse reasoning-opgaver  
  - Kræver mere prompt-tuning  

  ---

  ### **Claude 3.5 Sonnet**
  **Fordele:**
  - Meget stærk i komplekse analyser  
  - Høj faktuel nøjagtighed  
  - God struktur i JSON-output  

  **Afgrænsninger:**
  - Langsommere og dyrere  
  - Mere forsigtig → flere afvisninger  

  ---

  ### **GPT-4.1**
  **Fordele:**
  - Stærk reasoning-evne  
  - Stabil håndtering af schemaer  
  - Velegnet til klassifikation  

  **Afgrænsninger:**
  - Kan “overforklare” uden strikt schema  
  - Ikke helt så konsistent som Claude i lange dokumenter  

  ---

  ## Praktisk afprøvning og erfaringer

  Under testen af Gemini 2.5 oplevede jeg flere "503: Service Unavailable", som tyder på midlertidig overbelastning.

  **Billede**  
  /assets/images/error_503.png`

  Derfor skiftede jeg til Gemini 1.5, der var mere stabil – men som ikke understøtter strict JSON.

  **Billede**  
  /assets/images/strict_unavailable.png`

  Første version af prompten (PromptV0) gav chain-of-thought-lækage. Det blev løst ved at tilføje anti-CoT-instruktioner.

  **Billede**  
  /assets/images/promp_v0.png`

  Dette viser, at arbejdet med LLM’er kræver teknisk forståelse for modellens begrænsninger og evnen til at iterere på prompts og schemaer. Kombinationen af AI-kompetencer og backend-viden er afgørende for at skabe robuste løsninger.

next_plan: "Uge XX: Fortsat evaluering og udvikling af prompt, schema og modellens kvalitet i et praktisk pipeline-flow."
---
